from datetime import datetime
import numpy as np
import sounddevice as sd
import torch
from faster_whisper import WhisperModel
from scipy.signal import resample_poly
import keyboard
import queue
import time

# =============================
# ğŸ¯ ì„¤ì • ê°’
# =============================

MODEL_SIZE = "large-v3"               # whisper ëª¨ë¸ í¬ê¸° (small, medium, large ë“±)
DEVICE_ID = 1                         # ğŸ™ï¸ ì‚¬ìš©í•  microphone device index
CHANNELS = 1                           # mono (ë‹¨ì¼ ì±„ë„)
ENERGY_GATE_THRESHOLD = 0.0008          # âœ… ê°ë„: ë„ˆë¬´ ì¡°ìš©í•œ ë…¹ìŒì€ ë¬´ì‹œ
MAX_RECORD_SECONDS = 120                # âœ… ìµœëŒ€ ë…¹ìŒ ì‹œê°„ 3070ì€ 2ë¶„ë„˜ì–´ê°€ë©´ ë³€í™˜ì‹œê°„ì´ ë„ˆë¬´ì˜¤ë˜ê±¸ë¦¼

# =============================
# ğŸ§ ë””ë°”ì´ìŠ¤ ë° ëª¨ë¸ ì´ˆê¸°í™”
# =============================

device_info = sd.query_devices(DEVICE_ID, 'input')
SAMPLE_RATE = int(device_info['default_samplerate'])   # ğŸ™ï¸ ë§ˆì´í¬ ê¸°ë³¸ ìƒ˜í”Œë ˆì´íŠ¸

# whisper ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPU ì‚¬ìš©)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = WhisperModel(MODEL_SIZE, device=device, compute_type="float16")

print(f"\nğŸ™ï¸ ë””ë°”ì´ìŠ¤ {DEVICE_ID}: {device_info['name']} ({SAMPLE_RATE} Hz)")
print(f"âœ… Whisper {MODEL_SIZE} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})")
print("â–¶ scroll â†’ ë…¹ìŒ ì‹œì‘, pause â†’ ì¤‘ì§€ + ë³€í™˜ (Ctrl+C ì¢…ë£Œ)\n")

# =============================
# ğŸ™ï¸ ì „ì—­ ë³€ìˆ˜ ì •ì˜
# =============================

recording = False               # í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ ìƒíƒœ í‘œì‹œ
audio_queue = queue.Queue()     # ë…¹ìŒ ë°ì´í„°ë¥¼ ë‹´ëŠ” ë²„í¼ (stream ì½œë°± â†’ mainìœ¼ë¡œ ì „ë‹¬)

# =============================
# ğŸ™ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì½œë°± í•¨ìˆ˜
# =============================

def audio_callback(indata, frames, time_info, status):
    """
    ğŸ™ï¸ streamì´ ì¼œì ¸ ìˆëŠ” ë™ì•ˆ ê³„ì† í˜¸ì¶œë¨
    â†’ ë…¹ìŒ ë°ì´í„°ë¥¼ indataë¡œ ë°›ì•„ì„œ queueì— ì €ì¥
    """
    if recording:
        audio_queue.put(indata.copy())  # ì›ë³¸ ë°ì´í„° ë³µì‚¬ í›„ queueì— ì €ì¥

# =============================
# ğŸ™ï¸ ë…¹ìŒ ë°ì´í„° â†’ í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜
# =============================

def process_audio():
    audio_chunks = []
    total_samples = 0
    max_samples = SAMPLE_RATE * MAX_RECORD_SECONDS

    while not audio_queue.empty() and total_samples < max_samples:
        chunk = audio_queue.get()
        audio_chunks.append(chunk)
        total_samples += chunk.shape[0]

    if not audio_chunks:
        print("âš ï¸ ë…¹ìŒ ë°ì´í„° ì—†ìŒ.")
        return

    audio = np.concatenate(audio_chunks, axis=0).flatten()

    if np.mean(np.abs(audio)) < ENERGY_GATE_THRESHOLD:
        print("âš ï¸ ë„ˆë¬´ ì¡°ìš©í•´ì„œ ë¬´ì‹œë¨.")
        return

    if SAMPLE_RATE != 16000:
        audio = resample_poly(audio, up=16000, down=SAMPLE_RATE)

    # âœ… fast-whisper ìŠ¤íƒ€ì¼ë¡œ ìˆ˜ì •
    segments, info = model.transcribe(
        audio.astype(np.float32),
        language="ko",
        vad_filter=True,
        beam_size=1,
        temperature=0.0
    )

    print("[ë‹µë³€]:", end=" ")
    for segment in segments:
        print(segment.text.strip(), end=" ")
    print()


# =============================
# ğŸ¯ ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# =============================

if __name__ == "__main__":
    try:
        # ğŸ™ï¸ stream ì´ˆê¸°í™” â†’ í‚¤ ëˆ„ë¥¼ ë•Œë§Œ start/stop
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            device=DEVICE_ID,
            channels=CHANNELS,
            callback=audio_callback   # streamì—ì„œ ê³„ì† í˜¸ì¶œí•  ì½œë°± ë“±ë¡
        )

        # ğŸ¯ ë¬´í•œ ë£¨í”„: í‚¤ ì…ë ¥ ëŒ€ê¸°
        while True:
            # âœ… scroll lock í‚¤ ëˆ„ë¥´ë©´ â†’ stream ì‹œì‘
            if keyboard.is_pressed('scroll lock') and not recording:
                print(f"[{datetime.now().strftime('%H:%M:%S')}]ğŸ¬ ë…¹ìŒ ì‹œì‘ (scroll)")
                audio_queue.queue.clear()    # ì´ì „ ë²„í¼ ì´ˆê¸°í™” (ê¹¨ë—í•œ ì‹œì‘)
                stream.start()               # stream ì‹œì‘ â†’ ì½œë°±ìœ¼ë¡œ audio_queue ì±„ì›€
                recording = True
                time.sleep(0.5)              # í‚¤ ì¤‘ë³µ ì…ë ¥ ë°©ì§€ (ë””ë°”ìš´ìŠ¤)

            # âœ… pause í‚¤ ëˆ„ë¥´ë©´ â†’ stream ì •ì§€ + STT ë³€í™˜
            if keyboard.is_pressed('pause') and recording:
                print(f"[{datetime.now().strftime('%H:%M:%S')}]ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ + ë³€í™˜ ì‹œì‘ (pause)")
                stream.stop()                # stream ë©ˆì¶¤ â†’ ë” ì´ìƒ audio_queueì— ì•ˆ ë„£ìŒ
                recording = False
                process_audio()              # queueì— ë‚¨ì€ ë°ì´í„° â†’ STT ìˆ˜í–‰
                time.sleep(0.5)              # ì¤‘ë³µ ì…ë ¥ ë°©ì§€

    except KeyboardInterrupt:
        # âœ… Ctrl+C ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
        print("\nğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œë¨.")
        if recording:
            stream.stop()
