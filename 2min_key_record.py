from datetime import datetime
import numpy as np
import sounddevice as sd
import torch
import whisper
from scipy.signal import resample_poly
import keyboard
import queue
import time

# =============================
# ğŸ¯ ì„¤ì • ê°’
# =============================

MODEL_SIZE = "large-v3"               # whisper ëª¨ë¸ í¬ê¸° (small, medium, large ë“±)
DEVICE_ID = 14                         # ğŸ™ï¸ ì‚¬ìš©í•  microphone device index
CHANNELS = 1                           # mono (ë‹¨ì¼ ì±„ë„)
ENERGY_GATE_THRESHOLD = 0.001          # âœ… ê°ë„: ë„ˆë¬´ ì¡°ìš©í•œ ë…¹ìŒì€ ë¬´ì‹œ
MAX_RECORD_SECONDS = 120                # âœ… ìµœëŒ€ ë…¹ìŒ ì‹œê°„ 3070ì€ 2ë¶„ë„˜ì–´ê°€ë©´ ë³€í™˜ì‹œê°„ì´ ë„ˆë¬´ì˜¤ë˜ê±¸ë¦¼

# =============================
# ğŸ§ ë””ë°”ì´ìŠ¤ ë° ëª¨ë¸ ì´ˆê¸°í™”
# =============================

device_info = sd.query_devices(DEVICE_ID, 'input')
SAMPLE_RATE = int(device_info['default_samplerate'])   # ğŸ™ï¸ ë§ˆì´í¬ ê¸°ë³¸ ìƒ˜í”Œë ˆì´íŠ¸

# whisper ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPU ì‚¬ìš©)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model(MODEL_SIZE, device=device)

print(f"\nğŸ™ï¸ ë””ë°”ì´ìŠ¤ {DEVICE_ID}: {device_info['name']} ({SAMPLE_RATE} Hz)")
print(f"âœ… Whisper {MODEL_SIZE} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})")
print("â–¶ scroll â†’ ë…¹ìŒ ì‹œì‘, pause â†’ ì¤‘ì§€ + ë³€í™˜ (ìµœëŒ€ 1ë¶„, Ctrl+C ì¢…ë£Œ)\n")

# =============================
# ğŸ™ï¸ ì „ì—­ ë³€ìˆ˜ ì •ì˜
# =============================

recording = False               # í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ ìƒíƒœ í‘œì‹œ
audio_queue = queue.Queue()     # ë…¹ìŒ ë°ì´í„°ë¥¼ ë‹´ëŠ” ë²„í¼ (stream ì½œë°± â†’ mainìœ¼ë¡œ ì „ë‹¬)

# =============================
# ğŸ™ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì½œë°± í•¨ìˆ˜
# =============================

def audio_callback(indata, frames, time_info, status):
    """
    ğŸ™ï¸ streamì´ ì¼œì ¸ ìˆëŠ” ë™ì•ˆ ê³„ì† í˜¸ì¶œë¨
    â†’ ë…¹ìŒ ë°ì´í„°ë¥¼ indataë¡œ ë°›ì•„ì„œ queueì— ì €ì¥
    """
    if recording:
        audio_queue.put(indata.copy())  # ì›ë³¸ ë°ì´í„° ë³µì‚¬ í›„ queueì— ì €ì¥

# =============================
# ğŸ™ï¸ ë…¹ìŒ ë°ì´í„° â†’ í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜
# =============================

def process_audio():
    """
    ğŸ™ï¸ queueì— ì €ì¥ëœ ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ì„œ whisperë¡œ STT ìˆ˜í–‰
    """
    audio_chunks = []
    total_samples = 0
    max_samples = SAMPLE_RATE * MAX_RECORD_SECONDS   # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (60ì´ˆ)

    # queueì— ìŒ“ì¸ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    while not audio_queue.empty() and total_samples < max_samples:
        chunk = audio_queue.get()
        audio_chunks.append(chunk)
        total_samples += chunk.shape[0]   # í˜„ì¬ chunkì˜ ìƒ˜í”Œ ê°œìˆ˜ ë”í•˜ê¸°

    # ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¦¬í„´
    if not audio_chunks:
        print("âš ï¸ ë…¹ìŒ ë°ì´í„° ì—†ìŒ.")
        return

    # numpy arrayë¡œ ë³‘í•©
    audio = np.concatenate(audio_chunks, axis=0).flatten()

    # ë„ˆë¬´ ì¡°ìš©í•˜ë©´ (ë…¸ì´ì¦ˆ ìˆ˜ì¤€) â†’ ë³€í™˜í•˜ì§€ ì•Šê³  ì¢…ë£Œ
    if np.mean(np.abs(audio)) < ENERGY_GATE_THRESHOLD:
        print("âš ï¸ ë„ˆë¬´ ì¡°ìš©í•´ì„œ ë¬´ì‹œë¨.")
        return

    # whisper ëª¨ë¸ ì…ë ¥ì€ 16kHz â†’ í•„ìš” ì‹œ resample
    if SAMPLE_RATE != 16000:
        audio = resample_poly(audio, up=16000, down=SAMPLE_RATE)

    # whisper ëª¨ë¸ë¡œ STT ìˆ˜í–‰
    result = model.transcribe(
        audio.astype(np.float32),
        language="ko",                             # í•œêµ­ì–´ ê³ ì •
        fp16=True,                                # GPU ì‚¬ìš© ì‹œ ì†ë„ í–¥ìƒ
        temperature=0,
        condition_on_previous_text=False          # ì´ì „ ë¬¸ì¥ì— ì˜í–¥ X (ë…ë¦½ ë¬¸ì¥)
    )

    # ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì¶œë ¥
    print(f"[ë‹µë³€]:{result['text']}")

# =============================
# ğŸ¯ ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# =============================

if __name__ == "__main__":
    try:
        # ğŸ™ï¸ stream ì´ˆê¸°í™” â†’ í‚¤ ëˆ„ë¥¼ ë•Œë§Œ start/stop
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            device=DEVICE_ID,
            channels=CHANNELS,
            callback=audio_callback   # streamì—ì„œ ê³„ì† í˜¸ì¶œí•  ì½œë°± ë“±ë¡
        )

        # ğŸ¯ ë¬´í•œ ë£¨í”„: í‚¤ ì…ë ¥ ëŒ€ê¸°
        while True:
            # âœ… scroll lock í‚¤ ëˆ„ë¥´ë©´ â†’ stream ì‹œì‘
            if keyboard.is_pressed('scroll lock') and not recording:
                print(f"[{datetime.now().strftime('%H:%M:%S')}]ğŸ¬ ë…¹ìŒ ì‹œì‘ (scroll)")
                audio_queue.queue.clear()    # ì´ì „ ë²„í¼ ì´ˆê¸°í™” (ê¹¨ë—í•œ ì‹œì‘)
                stream.start()               # stream ì‹œì‘ â†’ ì½œë°±ìœ¼ë¡œ audio_queue ì±„ì›€
                recording = True
                time.sleep(0.5)              # í‚¤ ì¤‘ë³µ ì…ë ¥ ë°©ì§€ (ë””ë°”ìš´ìŠ¤)

            # âœ… pause í‚¤ ëˆ„ë¥´ë©´ â†’ stream ì •ì§€ + STT ë³€í™˜
            if keyboard.is_pressed('pause') and recording:
                print(f"[{datetime.now().strftime('%H:%M:%S')}]ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ + ë³€í™˜ ì‹œì‘ (pause)")
                stream.stop()                # stream ë©ˆì¶¤ â†’ ë” ì´ìƒ audio_queueì— ì•ˆ ë„£ìŒ
                recording = False
                process_audio()              # queueì— ë‚¨ì€ ë°ì´í„° â†’ STT ìˆ˜í–‰
                time.sleep(0.5)              # ì¤‘ë³µ ì…ë ¥ ë°©ì§€

    except KeyboardInterrupt:
        # âœ… Ctrl+C ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
        print("\nğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œë¨.")
        if recording:
            stream.stop()
