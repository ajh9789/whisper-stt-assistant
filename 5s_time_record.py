from datetime import datetime
import time
import numpy as np
import sounddevice as sd
import torch
import whisper
from scipy.signal import resample_poly

# =============================
# ğŸ¯ ì„¤ì • ê°’
# =============================

MODEL_SIZE = "medium"                  # small â†’ ë¹ ë¦„ / medium â†’ ì •í™•ë„ / large-v3 â†’ ë¬´ê±°ì›€
DEVICE_ID = 14                         # ğŸ™ï¸ ì‚¬ìš©í•  microphone device index
RECORD_SECONDS = 5                    # ğŸ™ï¸ ë…¹ìŒ ê¸¸ì´ (ì´ˆ)
CHANNELS = 1                           # mono
ENERGY_GATE_THRESHOLD = 0.001          # âœ… ë¯¼ê°ë„: ë‚®ìœ¼ë©´ ë¯¼ê° â†‘, ë†’ìœ¼ë©´ ë‘”ê° â†“

# =============================
# ğŸ§ ë””ë°”ì´ìŠ¤ ë° whisper ëª¨ë¸ ì´ˆê¸°í™”
# =============================

device_info = sd.query_devices(DEVICE_ID, 'input')
SAMPLE_RATE = int(device_info['default_samplerate'])    # ğŸ™ï¸ ë§ˆì´í¬ ìƒ˜í”Œë ˆì´íŠ¸

device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model(MODEL_SIZE, device=device)  # âœ… ëª¨ë¸ ë¡œë“œ

print(f"\nğŸ™ï¸ ë””ë°”ì´ìŠ¤ {DEVICE_ID}: {device_info['name']} ({SAMPLE_RATE} Hz)")
print(f"âœ… Whisper {MODEL_SIZE} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})")
print(f"ğŸ”„ {RECORD_SECONDS}ì´ˆë§ˆë‹¤ ìë™ ë…¹ìŒ + ë³€í™˜ ì‹œì‘ (Ctrl+Cë¡œ ì¤‘ì§€)\n")

# =============================
# ğŸ™ï¸ STT í•¨ìˆ˜
# =============================

def record_and_transcribe():
    """
    ğŸ™ï¸ nì´ˆ ë…¹ìŒ â†’ whisper STT ë³€í™˜
    """
    # print(f"ğŸ™ï¸ {RECORD_SECONDS}ì´ˆ ë…¹ìŒ ì¤‘...")
    audio = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE), samplerate=SAMPLE_RATE,
                   channels=CHANNELS, dtype='float32', device=DEVICE_ID)
    sd.wait()      # âœ… ë…¹ìŒ ì™„ë£Œ ëŒ€ê¸°
    audio = np.squeeze(audio)

    # âœ… ë¯¼ê°ë„ í•„í„°: í‰ê·  ì§„í­ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¬´ì‹œ
    avg_amplitude = np.mean(np.abs(audio))
    if avg_amplitude < ENERGY_GATE_THRESHOLD:
        return

    # âœ… whisper ì…ë ¥ìš© ë³€í™˜ (16kHz, float32)
    if SAMPLE_RATE != 16000:
        audio = resample_poly(audio, up=16000, down=SAMPLE_RATE)

    # print("ğŸ” whisper ë³€í™˜ ì¤‘...")

    # âœ… whisper STT
    result = model.transcribe(
        audio,
        language="ko",
        fp16=True,                           # âœ… GPU ì‚¬ìš© ì‹œ ì†ë„ í–¥ìƒ
        temperature=0,
        condition_on_previous_text=False
    )

    print(f"[{datetime.now().strftime('%H:%M:%S')}]:{result['text']}")

# =============================
# ğŸ¯ ë¬´í•œ ë°˜ë³µ
# =============================

if __name__ == "__main__":
    try:
        while True:
            record_and_transcribe()
            # time.sleep(0.1)     # âœ… ì•½ê°„ì˜ ëŒ€ê¸° (ì—°ì† ë…¹ìŒ ì•ˆì •í™”)
    except KeyboardInterrupt:
        print("\nğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œë¨.")